{"cells":[{"cell_type":"markdown","metadata":{"id":"jcionhVJzd5r"},"source":["# **Make Pretrained-Model FaceNet !**\n"]},{"cell_type":"markdown","metadata":{"id":"WE6nWiH8-i9q"},"source":["## 0.미션\n"]},{"cell_type":"markdown","metadata":{"id":"53bSTpVT-n_Y"},"source":["### (1) 미션1\n","여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 사전 학습 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 만들어야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n","- 2) 데이터셋을 전처리합니다.\n","    - Keras에는 **실제로 존재하는 이미지 데이터를 처리**해주는 함수가 있습니다."]},{"cell_type":"markdown","metadata":{"id":"DBjsZP8C-2Ra"},"source":["### (2) 미션2\n","데이터셋을 **학습에 적합한 형태**로 만들었다면, **FaceNet 모델로 Transfer Learning**을 수행합니다.\n","\n","- 1) FaceNet 모델 구조를 생성합니다.\n","    - [FaceNet 논문 링크](https://arxiv.org/abs/1503.03832)\n","    - FaceNet의 Input은 (160, 160) 사이즈의 이미지입니다.\n","- 2) FaceNet 모델 구조 + 구조 추가\n","    - FaceNet의 Output은 128차원의 벡터입니다.\n","    - 이 과정을 Transfer Learning라고 합니다."]},{"cell_type":"markdown","metadata":{"id":"K1eYbUCVUoox"},"source":["### (3) 미션3\n","학습된 모델로 추론하여 성능 지표를 확인하고 모델을 개선시키세요.\n","\n","그 후, 모델의 구조와 가중치를 **반드시 저장**하여 여러분의 노트북에 옮기세요.\n","\n","- 1) 다양한 모델을 사용해보세요.\n","    - 모델에 정해진 정답은 없습니다.\n","    - 성능 지표에서 무엇이 중요한지 깊게 생각하세요.\n","    - 사전 학습된 FaceNet 모델을 사용하셔도 좋고, 아예 독창적으로 여러분만의 모델을 만드셔도 좋습니다!\n","- 2) 모델을 **반드시 저장**하세요.\n","    - .keras 형태로 우선 Colab에 저장하세요.\n","    - Colab에 생성된 .keras 파일을 **로컬에 다운로드** 합니다."]},{"cell_type":"markdown","metadata":{"id":"WkDv7UfdYOgg"},"source":["## 1.환경설정"]},{"cell_type":"markdown","metadata":{"id":"mIxbiQ8wYOcy"},"source":["* 세부 요구사항\n","    - 경로 설정 : 구글콜랩\n","        * 구글 드라이브 바로 밑에 project4 폴더를 만드세요.\n","        * 데이터 파일을 복사해 넣습니다.\n","        * 필요하다고 판단되는 라이브러리를 추가하세요."]},{"cell_type":"markdown","metadata":{"id":"XIjpXC-xYHh3"},"source":["### (1) 경로 설정"]},{"cell_type":"markdown","metadata":{"id":"m6qgvZMSYcoX"},"source":["* 구글 드라이브 연결"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imfft4dGGJ2E"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPngJ_nwZPRC"},"outputs":[],"source":["path = '/content/drive/MyDrive/project4'"]},{"cell_type":"markdown","metadata":{"id":"SNEKwf_LY0JB"},"source":["### (2) 라이브러리 설치 및 불러오기"]},{"cell_type":"markdown","metadata":{"id":"xPwDW6e_Y0Fa"},"source":["* 라이브러리 로딩"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a4dS7tW-Zwrx"},"outputs":[],"source":["## colab에서 세션 재시작을 요구하는 팝업이 뜨면 재시작 누르세요.\n","!pip install keras-nightly"]},{"cell_type":"markdown","metadata":{"id":"Eg0gCl9Yatak"},"source":["## 3.미션1"]},{"cell_type":"markdown","metadata":{"id":"hPvTHwTmbKR5"},"source":["여러분은 노트북에서 얼굴 인식 파일을 실행시키기 위해 사전 학습 모델을 만들어야 합니다.\n","\n","그 전에 가지고 있는 데이터셋을 **학습에 적합한 형태**로 만들어야 합니다.\n","\n","- 1) 데이터셋을 불러옵니다.\n","    - 데이터셋은 2가지입니다. 본인의 얼굴 이미지 파일, 다른 사람의 얼굴 이미지 파일.\n","- 2) 데이터셋을 전처리합니다.\n","    - Keras에는 **실제로 존재하는 이미지 데이터를 처리**해주는 함수가 있습니다."]},{"cell_type":"markdown","metadata":{"id":"6rXSONrsatd5"},"source":["### (1) 데이터셋 불러오기"]},{"cell_type":"markdown","metadata":{"id":"VXLqxwNaathI"},"source":["* **세부 요구사항**\n","    - 데이터셋을 불러옵니다.\n","        - 데이터셋은 두 개의 압축 파일이어야 합니다.\n","            1. lfw-deepfunneled.zip : Labeled Faces in the Wild 데이터셋\n","            2. 여러분의 얼굴 이미지 데이터셋\n","                - 여러분의 얼굴 이미지가 담긴 **압축 파일**을 **Google Drive에 업로드** 하기를 권장합니다.\n","                    - 이미지 파일 하나하나 업로드 하면 시간이 오래 걸립니다.\n","    - 데이터셋 압축 파일을 **Colab에 폴더를 생성한 후 해제**하세요.\n","        - 데이터셋 폴더를 **본인 얼굴 폴더, LFW 폴더로 나누어** 생성하는 것을 권장합니다.\n","        - 만일 두 압축 파일을 하나의 폴더에 모두 해제하면 전처리가 더 까다로워질 것입니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - os, zipfile"]},{"cell_type":"markdown","metadata":{"id":"6OntGw5H-C3q"},"source":["#### 1) 본인 얼굴 이미지 데이터셋 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WOHNgVuV3ILU"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"fCDldok5ySsg"},"source":["#### 2) 다른 얼굴 이미지 데이터셋 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mPUwowZ53JK_"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"tJxTH37NiCM9"},"source":["### (2) 데이터셋 전처리\n","* **세부 요구사항**\n","    - 데이터셋을 전처리 합니다.\n","        - Training set, Validation set, Test set으로 데이터셋을 나누어 주세요.\n","            - 학습 과정에서 Training set, Validation set을 사용해야 합니다.\n","            - 추론 과정에서 Test set을 사용해야 합니다.\n","        - Keras의 **특정 함수**가 실제 존재하는 이미지 파일에 대한 전처리를 쉽게 도와줍니다.\n","        - **특정 함수**에서 요구하는 폴더 구조가 있습니다. **특정 함수**를 사용한다면 이에 맞춰서 폴더를 생성해야 합니다.\n","        - 각 데이터셋에 스케일링도 적용하세요.\n","    - 예시 코드에서 사용한 라이브러리\n","        - glob, random, shutil, numpy, keras"]},{"cell_type":"markdown","metadata":{"id":"kPI-FA1iiPoc"},"source":["#### 1) 데이터셋 분할"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z3ekDInu3J-x"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"BbKoJ7sqoGKe"},"source":["#### 2) **특정 함수** 사용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s2yqpVM0HryP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"9exWfPDX-2rT"},"source":["#### 3) 스케일링"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gn82guzH-2zY"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"w59u5Dtnrh5h"},"source":["## 4.미션2"]},{"cell_type":"markdown","metadata":{"id":"JHu91EoOrh2Q"},"source":["데이터셋을 **학습에 적합한 형태**로 만들었다면, **FaceNet 모델로 Transfer Learning**을 수행합니다.\n","\n","- 1) FaceNet 모델 구조를 생성합니다.\n","    - [FaceNet 논문 링크](https://arxiv.org/abs/1503.03832)\n","    - FaceNet의 Input은 (160, 160) 사이즈의 이미지입니다.\n","- 2) FaceNet 모델 구조 + 구조 추가\n","    - FaceNet의 Output은 128차원의 벡터입니다.\n","    - 이 과정을 Transfer Learning라고 합니다."]},{"cell_type":"markdown","metadata":{"id":"oEhBeJsarhxh"},"source":["### (1) FaceNet 구조 생성"]},{"cell_type":"markdown","metadata":{"id":"Zb-k_TFTsme6"},"source":["* **세부 요구사항**\n","    - FaceNet의 구조를 생성합니다.\n","        - FaceNet 구조 생성에 필요한 함수를 만듭니다.\n","    - FaceNet의 구조에 **잘 학습된 가중치**를 부여합니다.\n","        - FaceNet 원본 가중치 파일을 공유하였습니다.\n","    - (선택사항) FaceNet 모델의 가중치 업데이트를 방지합니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - numpy, functools, keras"]},{"cell_type":"markdown","metadata":{"id":"9jr2hiBBuDL_"},"source":["#### 1) 모델 구조 생성"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lZ3gbjSFyQfK"},"outputs":[],"source":["import numpy as np\n","from functools import partial\n","\n","\n","import keras\n","from keras.models import Model\n","\n","from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Activation\n","from keras.layers import BatchNormalization, Dropout, GlobalAveragePooling2D\n","from keras.layers import Lambda, Concatenate, add\n","\n","from keras import backend as K\n","from keras.saving import register_keras_serializable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFMvcMGUyQb_"},"outputs":[],"source":["@register_keras_serializable()\n","def scaling(x, scale):\n","    return x * scale\n","\n","@register_keras_serializable()\n","def conv2d_bn(x,\n","              filters,\n","              kernel_size,\n","              strides=1,\n","              padding='same',\n","              activation='relu',\n","              use_bias=False,\n","              name=None):\n","    x = Conv2D(filters,\n","               kernel_size,\n","               strides=strides,\n","               padding=padding,\n","               use_bias=use_bias,\n","               name=name)(x)\n","    if not use_bias:\n","        bn_axis = 1 if K.image_data_format() == 'channels_first' else 3\n","        bn_name = _generate_layer_name('BatchNorm', prefix=name)\n","        x = BatchNormalization(axis=bn_axis, momentum=0.995, epsilon=0.001,\n","                               scale=False, name=bn_name)(x)\n","    if activation is not None:\n","        ac_name = _generate_layer_name('Activation', prefix=name)\n","        x = Activation(activation, name=ac_name)(x)\n","    return x\n","\n","@register_keras_serializable()\n","def _generate_layer_name(name, branch_idx=None, prefix=None):\n","    if prefix is None:\n","        return None\n","    if branch_idx is None:\n","        return '_'.join((prefix, name))\n","    return '_'.join((prefix, 'Branch', str(branch_idx), name))\n","\n","@register_keras_serializable()\n","def _inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n","    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n","    if block_idx is None:\n","        prefix = None\n","    else:\n","        prefix = '_'.join((block_type, str(block_idx)))\n","    name_fmt = partial(_generate_layer_name, prefix=prefix)\n","\n","    if block_type == 'Block35':\n","        branch_0 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_1x1', 0))\n","        branch_1 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n","        branch_1 = conv2d_bn(branch_1, 32, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n","        branch_2 = conv2d_bn(x, 32, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n","        branch_2 = conv2d_bn(branch_2, 32, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n","        branch_2 = conv2d_bn(branch_2, 32, 3, name=name_fmt('Conv2d_0c_3x3', 2))\n","        branches = [branch_0, branch_1, branch_2]\n","    elif block_type == 'Block17':\n","        branch_0 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_1x1', 0))\n","        branch_1 = conv2d_bn(x, 128, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n","        branch_1 = conv2d_bn(branch_1, 128, [1, 7], name=name_fmt('Conv2d_0b_1x7', 1))\n","        branch_1 = conv2d_bn(branch_1, 128, [7, 1], name=name_fmt('Conv2d_0c_7x1', 1))\n","        branches = [branch_0, branch_1]\n","    elif block_type == 'Block8':\n","        branch_0 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_1x1', 0))\n","        branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n","        branch_1 = conv2d_bn(branch_1, 192, [1, 3], name=name_fmt('Conv2d_0b_1x3', 1))\n","        branch_1 = conv2d_bn(branch_1, 192, [3, 1], name=name_fmt('Conv2d_0c_3x1', 1))\n","        branches = [branch_0, branch_1]\n","    else:\n","        raise ValueError('Unknown Inception-ResNet block type. '\n","                         'Expects \"Block35\", \"Block17\" or \"Block8\", '\n","                         'but got: ' + str(block_type))\n","\n","    mixed = Concatenate(axis=channel_axis, name=name_fmt('Concatenate'))(branches)\n","    up = conv2d_bn(mixed,\n","                #    K.int_shape(x)[channel_axis],\n","                   x.shape[channel_axis],\n","                   1,\n","                   activation=None,\n","                   use_bias=True,\n","                   name=name_fmt('Conv2d_1x1'))\n","    up = Lambda(scaling,\n","                # output_shape=K.int_shape(up)[1:],\n","                output_shape=up.shape[1:],\n","                arguments={'scale': scale})(up)\n","    x = add([x, up])\n","    if activation is not None:\n","        x = Activation(activation, name=name_fmt('Activation'))(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DgI-eWQgyQZP"},"outputs":[],"source":["@register_keras_serializable()\n","def InceptionResNetV1(input_shape=(160, 160, 3),\n","                      classes=128,\n","                      dropout_keep_prob=0.8,\n","                      weights_path=None):\n","    inputs = Input(shape=input_shape)\n","    x = conv2d_bn(inputs, 32, 3, strides=2, padding='valid', name='Conv2d_1a_3x3')\n","    x = conv2d_bn(x, 32, 3, padding='valid', name='Conv2d_2a_3x3')\n","    x = conv2d_bn(x, 64, 3, name='Conv2d_2b_3x3')\n","    x = MaxPooling2D(3, strides=2, name='MaxPool_3a_3x3')(x)\n","    x = conv2d_bn(x, 80, 1, padding='valid', name='Conv2d_3b_1x1')\n","    x = conv2d_bn(x, 192, 3, padding='valid', name='Conv2d_4a_3x3')\n","    x = conv2d_bn(x, 256, 3, strides=2, padding='valid', name='Conv2d_4b_3x3')\n","\n","    # 5x Block35 (Inception-ResNet-A block):\n","    for block_idx in range(1, 6):\n","        x = _inception_resnet_block(x,\n","                                    scale=0.17,\n","                                    block_type='Block35',\n","                                    block_idx=block_idx)\n","\n","    # Mixed 6a (Reduction-A block):\n","    channel_axis = 1 if K.image_data_format() == 'channels_first' else 3\n","    name_fmt = partial(_generate_layer_name, prefix='Mixed_6a')\n","    branch_0 = conv2d_bn(x,\n","                         384,\n","                         3,\n","                         strides=2,\n","                         padding='valid',\n","                         name=name_fmt('Conv2d_1a_3x3', 0))\n","    branch_1 = conv2d_bn(x, 192, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n","    branch_1 = conv2d_bn(branch_1, 192, 3, name=name_fmt('Conv2d_0b_3x3', 1))\n","    branch_1 = conv2d_bn(branch_1,\n","                         256,\n","                         3,\n","                         strides=2,\n","                         padding='valid',\n","                         name=name_fmt('Conv2d_1a_3x3', 1))\n","    branch_pool = MaxPooling2D(3,\n","                               strides=2,\n","                               padding='valid',\n","                               name=name_fmt('MaxPool_1a_3x3', 2))(x)\n","    branches = [branch_0, branch_1, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='Mixed_6a')(branches)\n","\n","    # 10x Block17 (Inception-ResNet-B block):\n","    for block_idx in range(1, 11):\n","        x = _inception_resnet_block(x,\n","                                    scale=0.1,\n","                                    block_type='Block17',\n","                                    block_idx=block_idx)\n","\n","    # Mixed 7a (Reduction-B block): 8 x 8 x 2080\n","    name_fmt = partial(_generate_layer_name, prefix='Mixed_7a')\n","    branch_0 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 0))\n","    branch_0 = conv2d_bn(branch_0,\n","                         384,\n","                         3,\n","                         strides=2,\n","                         padding='valid',\n","                         name=name_fmt('Conv2d_1a_3x3', 0))\n","    branch_1 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 1))\n","    branch_1 = conv2d_bn(branch_1,\n","                         256,\n","                         3,\n","                         strides=2,\n","                         padding='valid',\n","                         name=name_fmt('Conv2d_1a_3x3', 1))\n","    branch_2 = conv2d_bn(x, 256, 1, name=name_fmt('Conv2d_0a_1x1', 2))\n","    branch_2 = conv2d_bn(branch_2, 256, 3, name=name_fmt('Conv2d_0b_3x3', 2))\n","    branch_2 = conv2d_bn(branch_2,\n","                         256,\n","                         3,\n","                         strides=2,\n","                         padding='valid',\n","                         name=name_fmt('Conv2d_1a_3x3', 2))\n","    branch_pool = MaxPooling2D(3,\n","                               strides=2,\n","                               padding='valid',\n","                               name=name_fmt('MaxPool_1a_3x3', 3))(x)\n","    branches = [branch_0, branch_1, branch_2, branch_pool]\n","    x = Concatenate(axis=channel_axis, name='Mixed_7a')(branches)\n","\n","    # 5x Block8 (Inception-ResNet-C block):\n","    for block_idx in range(1, 6):\n","        x = _inception_resnet_block(x,\n","                                    scale=0.2,\n","                                    block_type='Block8',\n","                                    block_idx=block_idx)\n","    x = _inception_resnet_block(x,\n","                                scale=1.,\n","                                activation=None,\n","                                block_type='Block8',\n","                                block_idx=6)\n","\n","    # Classification block\n","    x = GlobalAveragePooling2D(name='AvgPool')(x)\n","    x = Dropout(1.0 - dropout_keep_prob, name='Dropout')(x)\n","    # Bottleneck\n","    x = Dense(classes, use_bias=False, name='Bottleneck')(x)\n","    bn_name = _generate_layer_name('BatchNorm', prefix='Bottleneck')\n","    x = BatchNormalization(momentum=0.995, epsilon=0.001, scale=False,\n","                           name=bn_name)(x)\n","\n","    # Create model\n","    model = Model(inputs, x, name='inception_resnet_v1')\n","    if weights_path is not None:\n","        model.load_weights(weights_path)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPQVI80cyQWK"},"outputs":[],"source":[" = InceptionResNetV1()"]},{"cell_type":"markdown","metadata":{"id":"1UfZ2ZjVBKPq"},"source":["#### 2) 모델에 가중치 적용"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JeF72aRXyQQO"},"outputs":[],"source":["## FaceNet 가중치 파일 경로 설정\n","weights_path = path + ''\n","weights_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xrzp9pu0yQNW"},"outputs":[],"source":["## 가중치 파일 불러오기\n","loaded_weights = np.load(weights_path)\n","\n","loaded_weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6p8OaqDQyQKb"},"outputs":[],"source":["## FaceNet 각 레이어에 가중치 적용\n","facenet_model.set_weights([loaded_weights[key] for key in loaded_weights])"]},{"cell_type":"markdown","metadata":{"id":"3ji08O1bBmU1"},"source":["#### 3) 모델의 가중치 업데이트 방지 (선택사항)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_HW-n6qory5"},"outputs":[],"source":["## FaceNet 전체 레이어 확인\n","facenet_model.layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fl14ADvFBmRc"},"outputs":[],"source":["## FaceNet 전체 레이어 가중치 업데이트 방지\n","for l in facenet_model.layers :\n","    l.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"OSZ6BywVBsES"},"source":["### (2) 모델 구조 변형"]},{"cell_type":"markdown","metadata":{"id":"FdRPKS1FwVnp"},"source":["* **세부 요구사항**\n","    - 우리의 문제에 맞게 모델을 변형해야 합니다.\n","    - 예시 코드에서 사용한 라이브러리\n","        - keras"]},{"cell_type":"markdown","metadata":{"id":"Oj2q7vebwpky"},"source":["#### 1) 추가 모델링"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NEDV_p3V4Ajq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"QCjApw8XxJhT"},"source":["## 5.미션3"]},{"cell_type":"markdown","metadata":{"id":"Sr5Bh4TCwHbT"},"source":["학습된 모델로 추론하여 성능 지표를 확인하고 모델을 개선시키세요.\n","\n","그 후, 모델의 구조와 가중치를 **반드시 저장**하여 여러분의 노트북에 옮기세요.\n","\n","- 1) 다양한 모델을 사용해보세요.\n","    - 모델에 정해진 정답은 없습니다.\n","    - 성능 지표에서 무엇이 중요한지 깊게 생각하세요.\n","    - 사전 학습된 FaceNet 모델을 사용하셔도 좋고, 아예 독창적으로 여러분만의 모델을 만드셔도 좋습니다!\n","- 2) 모델을 **반드시 저장**하세요.\n","    - .keras 형태로 우선 Colab에 저장하세요.\n","    - Colab에 생성된 .keras 파일을 **로컬에 다운로드** 합니다."]},{"cell_type":"markdown","metadata":{"id":"9iEtx6mJxaCI"},"source":["### (1) 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"UVKBjLf4xeah"},"source":["* **세부 요구사항**\n","    - 모델 구조를 잘 변형하였다면, 학습도 진행해야 합니다.\n","        - Keras에서 지원하는 다양한 함수를 사용하세요.\n","    - 예시 코드에서 사용한 라이브러리\n","        - keras"]},{"cell_type":"markdown","metadata":{"id":"9P5R2_Tp0SGV"},"source":["#### 1) 학습에 유용한 함수 불러오기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IOHe2c_Q4QT1"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"84-AbpGw0WlD"},"source":["#### 2) 모델 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwyY85hqyC-L"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XsI5xF6ZyDCB"},"source":["### (2) 모델 추론"]},{"cell_type":"markdown","metadata":{"id":"UlUaGjUDyDFI"},"source":["* **세부 요구사항**\n","    - 학습된 모델의 성능을 확인해보세요.\n","        - 임계값 조절, 클래스 가중치 부여 등으로 모델의 성능을 높여보세요.\n","    - 예시 코드에서 사용한 라이브러리\n","        - keras, sklearn"]},{"cell_type":"markdown","metadata":{"id":"IUfy6T3-0up8"},"source":["#### 1) 모델 추론"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adRp8lItyDIJ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_5WwisIM09j8"},"source":["#### 2) 성능 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dyUpRugn4XZU"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ZAfyZM8By-O1"},"source":["### (3) 모델 저장"]},{"cell_type":"markdown","metadata":{"id":"mwLioXUOzHQ3"},"source":["* **세부 요구사항**\n","    - **반드시 반드시 모델을 저장하고 로컬에 다운로드하세요.**\n","    - 예시 코드에서 사용한 라이브러리\n","        - keras"]},{"cell_type":"markdown","metadata":{"id":"XcfJldRXy-SB"},"source":["#### 1) 모델 저장"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fkqY7P6Yy-Vn"},"outputs":[],"source":["## .keras로 저장해야 안전\n",".save('')"]},{"cell_type":"markdown","metadata":{"id":"lEvzoc8LzTMM"},"source":["#### 2) 저장된 모델 체크"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_zGkc_SzS6d"},"outputs":[],"source":["## Colab에 저장된 모델을 불러와 확인\n","temp_model = keras.saving.load_model('')\n","temp_model.summary()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPjahnrqdqTCYO809Vcd/Cj","mount_file_id":"14X1SQnhCehTXTGV_RYHi5i1EHeQGvDj1","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
